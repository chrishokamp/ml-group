{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from __future__ import division, print_function\n",
      "import numpy as np\n",
      "\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Tensors\n",
      "the tensor API contains many operations similar to the `numpy.*` namespace, and ndarrays in particular"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano import *\n",
      "import theano.tensor as T\n",
      "# don't worry if you get a cutils_ext error here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[autoreload of cutils_ext failed: Traceback (most recent call last):\n",
        "  File \"/home/chris/.local/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 229, in check\n",
        "    superreload(m, reload, self.old_objects)\n",
        "ImportError: No module named cutils_ext\n",
        "]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question: what is a tensor?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[the tensor documentation](http://deeplearning.net/software/theano/library/tensor/basic.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a function to add two scalars\n",
      "x = T.scalar()\n",
      "y = T.scalar()\n",
      "# or:\n",
      "# x,y = T.scalars()\n",
      "z = x + y\n",
      "add = function([x,y], z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[visualization of a symbolic operation](http://deeplearning.net/software/theano/tutorial/symbolic_graphs.html#tutorial-graphfigure)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "add(3,4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array(7.0)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = T.dmatrix('x')\n",
      "y = x * 2."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.owner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Elemwise{mul,no_inplace}(x, DimShuffle{x,x}.0)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question: why the error here?\n",
      "y(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'TensorVariable' object is not callable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-1c3da606adb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Question: why the error here?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: 'TensorVariable' object is not callable"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mult = function([x], y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_by_two = np.ones((1,2)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mult(one_by_two)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([[ 2.,  2.]])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a full logistic regression example\n",
      "import numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "rng = numpy.random\n",
      "\n",
      "N = 400\n",
      "feats = 784\n",
      "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n",
      "training_steps = 10000\n",
      "\n",
      "# Declare Theano symbolic variables\n",
      "# the name parameter is optional, but it's useful if we need to debug something complicated\n",
      "x = T.matrix(\"x\")\n",
      "y = T.vector(\"y\")\n",
      "w = theano.shared(rng.randn(feats), name=\"w\")\n",
      "b = theano.shared(0., name=\"b\")\n",
      "\n",
      "\n",
      "# Construct Theano expression graph\n",
      "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))   # Probability that target = 1\n",
      "prediction = p_1 > 0.5                    # The prediction thresholded\n",
      "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function\n",
      "cost = xent.mean() + 0.01 * (w ** 2).sum()# The cost to minimize\n",
      "gw, gb = T.grad(cost, [w, b])             # Compute the gradient of the cost\n",
      "                                         \n",
      "\n",
      "# Compile\n",
      "train = theano.function(\n",
      "          inputs=[x,y],\n",
      "          outputs=[prediction, xent],\n",
      "          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))\n",
      "predict = theano.function(inputs=[x], outputs=prediction)\n",
      "\n",
      "# Train\n",
      "for i in range(training_steps):\n",
      "    pred, err = train(D[0], D[1])\n",
      "\n",
      "# updates (iterable over pairs (shared_variable, new_expression). List, tuple or dict.) \u2013 expressions for new SharedVariable values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Theano already has [several implementations](http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html) of the sigmoid function available "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Discuss: T.grad"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "actual = D[1]\n",
      "predicted = predict(D[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "confusion_matrix(actual, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([[189,   0],\n",
        "       [  0, 211]])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercises \n",
      "\n",
      "- write a function which divides two scalars\n",
      "    - modify this function to do elementwise division of any n-order tensor\n",
      "- write a function which takes two vectors $\\theta$ and $x$ and computes the sigmoid -- $ sigmoid(x) = \\frac{1}{1+\\exp(-\\theta \\cdot x)}$ \n",
      "    - hint - you can use the T.dot function\n",
      "- Substitute an [sklearn dataset](http://scikit-learn.org/stable/datasets/#toy-datasets) for the fake data above, and check performance\n",
      "    - remember to evaluate on a test set if you want to see the real performance\n",
      "\n",
      "- Find the gradient computation and the parameter update in the multilayer perceptron example\n",
      "- Add [regularization](http://deeplearning.net/tutorial/gettingstarted.html#l1-l2-regularization) to the LR implementation above\n",
      "- Add a layer to the [multilayer perceptron](http://deeplearning.net/tutorial/mlp.html)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}